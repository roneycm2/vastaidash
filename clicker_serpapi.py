"""
Google Ads Clicker - SerpApi Google Ads API + Patchright
Usa a API oficial do SerpApi para buscar an√∫ncios e Patchright para clicar
"""

import asyncio
import random
import time
import json
import tempfile
import threading
from urllib.parse import urlparse

from serpapi import GoogleSearch
from patchright.async_api import async_playwright

from stats_serpapi import stats_manager
from dashboard_serpapi import iniciar_dashboard_thread

# =====================================================
# CONFIGURA√á√ïES
# =====================================================
SERPAPI_KEY = "bc8250eea3f0d6305d9adb605a1b10d5378fde18f805c3b48b6bbcd1e48da1b9"

PROXY_HOST = "fb29d01db8530b99.shg.na.pyproxy.io"
PROXY_PORT = "16666"
PROXY_USER = "liderbet1-zone-resi-region-br-session-85deaca4d5ea-sessTime-1"
PROXY_PASS = "Aa10203040"

PALAVRAS_ARQUIVO = "palavras_chave.txt"
DOMINIOS_PERMITIDOS_ARQUIVO = "dominios_permitidos.txt"

NUM_WORKERS = 15
DELAY_MIN = 2.0
DELAY_MAX = 5.0

# =====================================================
# VARI√ÅVEIS GLOBAIS
# =====================================================
DOMINIOS_PERMITIDOS = []
DOMINIOS_CLICADOS_GLOBAL = set()
DOMINIOS_CLICADOS_LOCK = threading.Lock()
ANUNCIOS_QUEUE = []
ANUNCIOS_QUEUE_LOCK = threading.Lock()


def carregar_palavras_chave(arquivo: str) -> list[str]:
    """Carrega palavras-chave do arquivo."""
    palavras = []
    try:
        with open(arquivo, "r", encoding="utf-8") as f:
            for linha in f:
                linha = linha.strip()
                if linha and not linha.startswith("#"):
                    palavras.append(linha)
    except FileNotFoundError:
        print(f"‚ùå Arquivo '{arquivo}' n√£o encontrado!")
    return palavras


def carregar_dominios_permitidos(arquivo: str) -> list[str]:
    """Carrega dom√≠nios permitidos do arquivo."""
    dominios = []
    try:
        with open(arquivo, "r", encoding="utf-8") as f:
            for linha in f:
                linha = linha.strip()
                if linha and not linha.startswith("#"):
                    dominios.append(linha.lower())
    except FileNotFoundError:
        pass
    return dominios


def extrair_dominio(url: str) -> str:
    """Extrai dom√≠nio de uma URL."""
    try:
        return urlparse(url).netloc.lower()
    except:
        return ""


def verificar_dominio_valido(href: str) -> tuple[bool, str]:
    """Verifica se dom√≠nio √© v√°lido para clicar."""
    global DOMINIOS_CLICADOS_GLOBAL
    
    dominio = extrair_dominio(href)
    if not dominio:
        return False, ""
    
    # Verifica se √© permitido
    if DOMINIOS_PERMITIDOS:
        if not any(p in dominio for p in DOMINIOS_PERMITIDOS):
            return False, dominio
    
    # Verifica se j√° foi clicado (thread-safe)
    with DOMINIOS_CLICADOS_LOCK:
        if dominio in DOMINIOS_CLICADOS_GLOBAL:
            return False, dominio
    
    return True, dominio


def marcar_dominio_clicado(dominio: str):
    """Marca dom√≠nio como clicado (thread-safe)."""
    with DOMINIOS_CLICADOS_LOCK:
        DOMINIOS_CLICADOS_GLOBAL.add(dominio)


def buscar_anuncios_serpapi(palavra_chave: str, debug: bool = False) -> list[dict]:
    """
    Busca an√∫ncios usando SerpApi Google Ads API.
    Retorna lista de an√∫ncios com link, t√≠tulo e tracking_link.
    """
    anuncios = []
    
    try:
        # Par√¢metros usando o formato oficial do SerpApi
        params = {
            "q": palavra_chave,
            "location": "Sao Paulo, State of Sao Paulo, Brazil",
            "hl": "pt",
            "gl": "br",
            "api_key": SERPAPI_KEY
        }
        
        # Realiza a busca usando a biblioteca oficial
        search = GoogleSearch(params)
        results = search.get_dict()
        
        # Debug: mostra se h√° erro na API
        if "error" in results:
            print(f"      ‚ùå Erro API: {results['error']}")
            return []
        
        # Debug: mostra quantos an√∫ncios a API retornou
        if debug:
            ads_count = len(results.get("ads", []))
            ads_bottom_count = len(results.get("ads_bottom", []))
            shopping_count = len(results.get("shopping_results", []))
            print(f"      üìä API retornou: {ads_count} ads, {ads_bottom_count} ads_bottom, {shopping_count} shopping")
        
        # Extrai an√∫ncios do topo (ads) - Google Ads Results
        if "ads" in results:
            for ad in results["ads"]:
                # Link principal do an√∫ncio
                link = ad.get("link", "")
                # Link de rastreamento (clique real do Google Ads)
                tracking_link = ad.get("tracking_link", link)
                titulo = ad.get("title", "")
                descricao = ad.get("description", "")
                displayed_link = ad.get("displayed_link", "")
                
                if link:
                    anuncios.append({
                        "link": link,
                        "tracking_link": tracking_link,
                        "titulo": titulo,
                        "descricao": descricao,
                        "displayed_link": displayed_link,
                        "palavra_chave": palavra_chave,
                        "tipo": "ads"
                    })
        
        # Extrai an√∫ncios do rodap√© (ads_bottom)
        if "ads_bottom" in results:
            for ad in results["ads_bottom"]:
                link = ad.get("link", "")
                tracking_link = ad.get("tracking_link", link)
                titulo = ad.get("title", "")
                
                if link:
                    anuncios.append({
                        "link": link,
                        "tracking_link": tracking_link,
                        "titulo": titulo,
                        "descricao": ad.get("description", ""),
                        "displayed_link": ad.get("displayed_link", ""),
                        "palavra_chave": palavra_chave,
                        "tipo": "ads_bottom"
                    })
        
        # Extrai an√∫ncios de shopping
        if "shopping_results" in results:
            for item in results["shopping_results"][:5]:
                link = item.get("link", "")
                if link:
                    anuncios.append({
                        "link": link,
                        "tracking_link": link,
                        "titulo": item.get("title", ""),
                        "descricao": f"Pre√ßo: {item.get('price', 'N/A')}",
                        "displayed_link": item.get("source", ""),
                        "palavra_chave": palavra_chave,
                        "tipo": "shopping"
                    })
        
        # Extrai an√∫ncios inline shopping
        if "inline_shopping" in results:
            for item in results["inline_shopping"][:3]:
                link = item.get("link", "")
                if link:
                    anuncios.append({
                        "link": link,
                        "tracking_link": link,
                        "titulo": item.get("title", ""),
                        "descricao": f"Pre√ßo: {item.get('price', 'N/A')}",
                        "displayed_link": item.get("source", ""),
                        "palavra_chave": palavra_chave,
                        "tipo": "inline_shopping"
                    })
        
    except Exception as e:
        print(f"‚ùå Erro SerpApi para '{palavra_chave}': {e}")
    
    return anuncios


def coletar_todos_anuncios(palavras: list[str]) -> list[dict]:
    """Coleta todos os an√∫ncios de todas as palavras-chave usando SerpApi."""
    todos_anuncios = []
    
    # Registra in√≠cio da coleta no stats
    stats_manager.add_log(f"üîç Iniciando busca de an√∫ncios para {len(palavras)} palavras-chave")
    
    print(f"\nüîç Buscando an√∫ncios via SerpApi Google Ads API...")
    print(f"   {len(palavras)} palavras-chave para processar\n")
    
    for i, palavra in enumerate(palavras):
        print(f"  [{i+1}/{len(palavras)}] Buscando: {palavra[:50]}...")
        
        # Ativa debug nas primeiras 3 buscas
        anuncios = buscar_anuncios_serpapi(palavra, debug=(i < 3))
        
        # Registra busca no stats
        anuncios_validos_count = 0
        anuncios_total_count = 0
        
        # Filtra apenas dom√≠nios v√°lidos
        for anuncio in anuncios:
            dominio = extrair_dominio(anuncio["link"])
            anuncios_total_count += 1
            
            # Mostra todos os dom√≠nios encontrados (para debug)
            if i < 3:  # Debug nas primeiras 3 buscas
                tipo = anuncio.get("tipo", "ads")
                print(f"      üîç [{tipo}] {dominio}")
            
            valido, dominio = verificar_dominio_valido(anuncio["link"])
            if valido and dominio:
                anuncio["dominio"] = dominio
                todos_anuncios.append(anuncio)
                anuncios_validos_count += 1
                tipo = anuncio.get("tipo", "ads")
                print(f"      ‚úÖ [{tipo}] {dominio} (PERMITIDO)")
        
        # Registra busca no SerpApi
        stats_manager.registrar_busca_serpapi(palavra, anuncios_validos_count)
        
        # Pequeno delay entre requisi√ß√µes
        time.sleep(0.3)
    
    # Remove duplicatas por dom√≠nio
    dominios_vistos = set()
    anuncios_unicos = []
    for anuncio in todos_anuncios:
        if anuncio["dominio"] not in dominios_vistos:
            dominios_vistos.add(anuncio["dominio"])
            anuncios_unicos.append(anuncio)
    
    print(f"\nüìä Resumo:")
    print(f"   Total de an√∫ncios encontrados: {len(todos_anuncios)}")
    print(f"   An√∫ncios √∫nicos (sem duplicatas): {len(anuncios_unicos)}")
    
    # Registra conclus√£o no stats
    stats_manager.add_log(f"‚úÖ Busca conclu√≠da: {len(anuncios_unicos)} an√∫ncios √∫nicos encontrados")
    
    return anuncios_unicos


def obter_proximo_anuncio(total_anuncios: int) -> dict | None:
    """Obt√©m pr√≥ximo an√∫ncio da fila (thread-safe)."""
    with ANUNCIOS_QUEUE_LOCK:
        if ANUNCIOS_QUEUE:
            anuncio = ANUNCIOS_QUEUE.pop(0)
            # Atualiza estat√≠sticas da fila
            stats_manager.atualizar_fila(total_anuncios, len(ANUNCIOS_QUEUE))
            return anuncio
    return None


async def verificar_proxy(page, worker_id: int) -> bool:
    """Verifica se o proxy est√° funcionando."""
    try:
        await page.goto('https://ipinfo.io/json', wait_until='networkidle')
        
        body = await page.locator('body').inner_text()
        data = json.loads(body)
        
        ip = data.get('ip', '')
        cidade = data.get('city', '')
        estado = data.get('region', '')
        pais = data.get('country', '')
        
        stats_manager.atualizar_ip(worker_id, ip, cidade, estado)
        print(f"  [Worker {worker_id}] IP: {ip} ({cidade}, {estado}, {pais})")
        
        return pais == 'BR'
    except Exception as e:
        print(f"  [Worker {worker_id}] Erro ao verificar proxy: {e}")
        return False


async def clicar_anuncio(page, worker_id: int, anuncio: dict) -> bool:
    """
    Clica em um an√∫ncio usando o tracking_link para simular clique real.
    """
    # Usa tracking_link se dispon√≠vel (clique real do Google Ads)
    link = anuncio.get("tracking_link", anuncio["link"])
    dominio = anuncio["dominio"]
    palavra = anuncio.get("palavra_chave", "")
    tipo = anuncio.get("tipo", "ads")
    
    try:
        stats_manager.atualizar_status(worker_id, f"clicando: {dominio[:20]}")
        stats_manager.atualizar_palavra(worker_id, f"[{tipo}] {palavra[:30]}")
        
        print(f"  [Worker {worker_id}] üñ±Ô∏è [{tipo}] Navegando para: {dominio}")
        
        # Navega para o link do an√∫ncio (tracking_link)
        try:
            await page.goto(link, wait_until='domcontentloaded', timeout=30000)
        except Exception as e:
            # Timeout √© comum, continuamos mesmo assim
            pass
        
        # Simula tempo de leitura na p√°gina (comportamento humano)
        tempo_leitura = random.uniform(8, 20)
        await asyncio.sleep(tempo_leitura)
        
        # Simula intera√ß√µes humanas
        try:
            # Scroll para baixo
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight * 0.3)")
            await asyncio.sleep(random.uniform(1, 2))
            
            # Scroll mais
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight * 0.6)")
            await asyncio.sleep(random.uniform(1, 2))
            
            # Move mouse aleatoriamente
            await page.mouse.move(
                random.randint(100, 800),
                random.randint(100, 600)
            )
        except:
            pass
        
        # Registra clique
        marcar_dominio_clicado(dominio)
        stats_manager.registrar_clique(worker_id, dominio, tempo_leitura)
        
        print(f"  [Worker {worker_id}] ‚úÖ Clique registrado: {dominio} (tempo: {tempo_leitura:.1f}s)")
        
        return True
        
    except Exception as e:
        print(f"  [Worker {worker_id}] ‚ùå Erro ao clicar em {dominio}: {e}")
        stats_manager.registrar_erro(worker_id, str(e))
        return False


async def worker_async(worker_id: int, total_anuncios: int):
    """
    Worker ass√≠ncrono que processa an√∫ncios da fila.
    """
    stats_manager.registrar_worker(worker_id)
    stats_manager.atualizar_status(worker_id, "iniciando")
    
    print(f"  [Worker {worker_id}] Iniciando browser...")
    
    # Cria diret√≥rio tempor√°rio que ser√° exclu√≠do automaticamente ao sair
    with tempfile.TemporaryDirectory() as user_data_dir:
        print(f"  [Worker {worker_id}] üìÅ Diret√≥rio tempor√°rio criado")
        
        async with async_playwright() as p:
            # Lan√ßa browser com proxy
            browser = await p.chromium.launch_persistent_context(
                user_data_dir,
                headless=False,
                proxy={
                    "server": f"http://{PROXY_HOST}:{PROXY_PORT}",
                    "username": PROXY_USER,
                    "password": PROXY_PASS
                },
                args=[
                    '--no-sandbox',
                    '--disable-blink-features=AutomationControlled',
                ],
                viewport={"width": 1366, "height": 768},
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            )
            
            print(f"  [Worker {worker_id}] ‚úÖ Browser iniciado!")
            
            # Cria nova p√°gina
            page = await browser.new_page()
            
            # Desabilita timeout de navega√ß√£o
            page.set_default_navigation_timeout(0)
            
            # Verifica proxy
            stats_manager.atualizar_status(worker_id, "verificando proxy")
            proxy_ok = await verificar_proxy(page, worker_id)
            print(f"  [Worker {worker_id}] Proxy BR: {proxy_ok}")
            
            # Processa an√∫ncios da fila
            cliques = 0
            while True:
                anuncio = obter_proximo_anuncio(total_anuncios)
                
                if anuncio is None:
                    print(f"  [Worker {worker_id}] üì≠ Fila vazia, finalizando...")
                    break
                
                sucesso = await clicar_anuncio(page, worker_id, anuncio)
                
                if sucesso:
                    cliques += 1
                
                # Delay entre cliques
                await asyncio.sleep(random.uniform(DELAY_MIN, DELAY_MAX))
            
            stats_manager.atualizar_status(worker_id, f"finalizado ({cliques} cliques)")
            
            # Fecha browser
            await browser.close()
        
        print(f"  [Worker {worker_id}] üóëÔ∏è Diret√≥rio tempor√°rio exclu√≠do!")
    
    print(f"  [Worker {worker_id}] ‚úÖ Finalizado com {cliques} cliques!")


def worker_thread(worker_id: int, total_anuncios: int):
    """Thread wrapper para worker ass√≠ncrono."""
    asyncio.run(worker_async(worker_id, total_anuncios))


def main():
    global DOMINIOS_PERMITIDOS, ANUNCIOS_QUEUE
    
    print("=" * 65)
    print("üéØ Google Ads Clicker - SerpApi Google Ads API + Patchright")
    print("   Busca an√∫ncios via API oficial + Cliques via browser")
    print("=" * 65)
    
    # Carrega configura√ß√µes
    palavras = carregar_palavras_chave(PALAVRAS_ARQUIVO)
    if not palavras:
        print("‚ùå Nenhuma palavra-chave encontrada!")
        return
    
    DOMINIOS_PERMITIDOS = carregar_dominios_permitidos(DOMINIOS_PERMITIDOS_ARQUIVO)
    
    print(f"\nüìã Configura√ß√µes:")
    print(f"   Palavras-chave: {len(palavras)}")
    print(f"   Dom√≠nios permitidos: {len(DOMINIOS_PERMITIDOS)}")
    print(f"   Workers paralelos: {NUM_WORKERS}")
    print(f"   Proxy: {PROXY_HOST}:{PROXY_PORT}")
    print(f"   SerpApi Key: {SERPAPI_KEY[:20]}...")
    
    # Inicia dashboard ANTES de coletar an√∫ncios
    print("\nüåê Iniciando dashboard...")
    iniciar_dashboard_thread()
    print("‚úÖ Dashboard: http://localhost:5000")
    time.sleep(1)  # Aguarda dashboard iniciar
    
    # Coleta todos os an√∫ncios via SerpApi
    anuncios = coletar_todos_anuncios(palavras)
    
    if not anuncios:
        print("‚ùå Nenhum an√∫ncio encontrado!")
        return
    
    # Preenche a fila de an√∫ncios
    ANUNCIOS_QUEUE = anuncios.copy()
    total_anuncios = len(anuncios)
    
    # Atualiza estat√≠sticas iniciais da fila
    stats_manager.atualizar_fila(total_anuncios, total_anuncios)
    
    # Ajusta n√∫mero de workers se tiver poucos an√∫ncios
    num_workers_efetivo = min(NUM_WORKERS, len(anuncios))
    
    # Inicia workers
    print(f"\nüöÄ Iniciando {num_workers_efetivo} workers para {len(anuncios)} an√∫ncios...")
    threads = []
    
    for i in range(num_workers_efetivo):
        t = threading.Thread(
            target=worker_thread,
            args=(i + 1, total_anuncios),
            daemon=True
        )
        threads.append(t)
        t.start()
        time.sleep(1)  # Intervalo entre inicializa√ß√µes
    
    print("\n‚úÖ Todos os workers iniciados!")
    print("üìä Acompanhe o progresso em: http://localhost:5000")
    print("\nPressione Ctrl+C para parar...\n")
    
    try:
        for t in threads:
            t.join()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Parando...")
    
    print("\n" + "=" * 65)
    print("‚úÖ Finalizado!")
    print("=" * 65)


if __name__ == "__main__":
    main()
